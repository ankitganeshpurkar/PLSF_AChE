{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression model\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "#modules\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.layers import Dense, Activation, Embedding, Flatten, LeakyReLU, BatchNormalization, Dropout\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os, random, shutil, logging, datetime, pickle,io, winsound, joblib\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Linear regression model\")\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "try:\n",
    "    #Disable all GPUS\n",
    "    tf.config.set_visible_devices([], 'GPU'),\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        assert device.device_type != 'GPU'\n",
    "except:\n",
    "    #Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q2f1(y_test, y_pred2, y_train):\n",
    "    '''R2 for test set or Q2f1'''\n",
    "    mean_y_train = np.mean(y_train)\n",
    "    num, den = 0, 0\n",
    "    y_test = list(y_test)\n",
    "    for i in range(len(y_test)):\n",
    "        num = num + ((y_test[i] - y_pred2[i])**2)\n",
    "        den = den + ((y_test[i] - mean_y_train)**2)\n",
    "    r2test = (1 -(num/den))\n",
    "    print(r2test)\n",
    "    return r2test[0]\n",
    "\n",
    "def Q2f2(y_test, y_pred2):\n",
    "    '''R2 for test set or Q2f2'''\n",
    "    mean_y_test = np.mean(y_test)\n",
    "    num, den = 0, 0\n",
    "    y_test = list(y_test)\n",
    "    for i in range(len(y_test)):\n",
    "        num = num + ((y_test[i] - y_pred2[i])**2)\n",
    "        den = den + ((y_test[i] - mean_y_test)**2)\n",
    "    r2test = (1 -(num/den))\n",
    "    print(r2test)\n",
    "    return r2test[0]\n",
    "\n",
    "    \n",
    "def maecr(y_test, y_pred2, y_train):\n",
    "    y_test = list(y_test)\n",
    "    \n",
    "    min1 = y_train.min()\n",
    "    max1 = y_train.max()\n",
    "    rang = max1-min1\n",
    "    \n",
    "    n = len(y_test)\n",
    "    m = len(y_pred2)\n",
    "    ma, sd = 0,0\n",
    "    for i, j in zip(range(n),range(m)):\n",
    "        ma = ma + np.abs(y_test[i] - y_pred2[j])\n",
    "        \n",
    "    mae = ma/n\n",
    "    \n",
    "    for i, j in zip(range(n),range(m)):\n",
    "        sd = sd + ((np.abs(y_test[i] - y_pred2[j])-mae)**2)\n",
    "    \n",
    "    sd1 = np.sqrt(sd/n)\n",
    "         \n",
    "    if (mae <= (0.1*rang)) and ((mae+(3*sd1)) <= (0.2*rang)):\n",
    "        val = 'GOOD'\n",
    "        \n",
    "    elif (mae > (0.15*rang)) or ((mae+(3*sd1)) > (0.25*rang)): \n",
    "        val = 'BAD'\n",
    "        \n",
    "    else:\n",
    "        val = 'MODERATE'\n",
    "        \n",
    "    return val\n",
    "\n",
    "def maecr_95(y_test, y_pred2, y_train):\n",
    "    y_test1 = pd.DataFrame()\n",
    "    for i in y_test.index:\n",
    "        y_test1 = y_test1.append({'activity' : y_test[i]}, ignore_index = True)\n",
    "    \n",
    "    y_pred2_df = pd.DataFrame()\n",
    "    for i in range(len(y_pred2)):\n",
    "        y_pred2_df = y_pred2_df.append({'activity' : y_pred2[i]}, ignore_index = True)\n",
    "        \n",
    "    \n",
    "    \n",
    "    min1 = y_train.min()\n",
    "    max1 = y_train.max()\n",
    "    rang = max1-min1\n",
    "    \n",
    "    n = len(y_test)\n",
    "    ma, sd = 0,0\n",
    "    m1 =  int(0.05*n)\n",
    "    df_abs = pd.DataFrame()\n",
    "    \n",
    "    for i in range(n):\n",
    "        df_abs = df_abs.append({'Absolute_error': float(np.abs(y_test1.iloc[i,0] - y_pred2_df.iloc[i,0]))},ignore_index=True)\n",
    "    #print(df_abs)   \n",
    "    index = df_abs.nlargest(m1,'Absolute_error').index\n",
    "    \n",
    "    y_test1 = y_test1.drop(axis=0, index=index)\n",
    "    y_pred2_df = y_pred2_df.drop(axis=0, index=index)\n",
    "    index1 = y_pred2_df.index\n",
    "   \n",
    "    n = len(index1)\n",
    "    for i in index1:\n",
    "        ma = ma + np.abs(y_test1['activity'].loc[i] - y_pred2_df['activity'].loc[i])\n",
    "        #print(ma)\n",
    "        \n",
    "    mae = ma/n\n",
    "    \n",
    "    for i in index1:\n",
    "        sd = sd + ((np.abs(y_test1['activity'].loc[i] - y_pred2_df['activity'].loc[i])-mae)**2)\n",
    "    \n",
    "    sd1 = np.sqrt(sd/n)\n",
    "         \n",
    "    if (mae <= (0.1*rang)) and ((mae+(3*sd1)) <= (0.2*rang)):\n",
    "        val = 'GOOD'\n",
    "        #print(mae, 0.1*rang, mae+(3*sd1),0.2*rang)\n",
    "    elif (mae > (0.15*rang)) or ((mae+(3*sd1)) > (0.25*rang)): \n",
    "        val = 'BAD'\n",
    "        #print(mae, 0.15*rang, mae+(3*sd1), 0.25*rang)\n",
    "    else:\n",
    "        val = 'MODERATE'\n",
    "        \n",
    "    return val\n",
    "\n",
    "def tropsha(y_train, y_test, y_pred1, y_pred2):\n",
    "    r2_score(y_train, y_pred1)\n",
    "    av_yta = np.mean(y_test)\n",
    "    av_ytp = np.mean(y_pred1)\n",
    "    k1, k2 = 0, 0\n",
    "    y_train = list(y_train)\n",
    "    y_pred1 = list(y_pred1)\n",
    "    sum1, sum2 = 0,0\n",
    "    for i in range(len(y_train)):\n",
    "        sum1 = sum1 + (y_train[i]*y_pred1[i])\n",
    "        sum2 = sum2 + (y_pred1[i]**2)\n",
    "    k1 = sum1/sum2\n",
    "    sum1, sum2 = 0,0\n",
    "    for i in range(len(y_train)):\n",
    "        sum1 = sum1 + (y_train[i]*y_pred1[i])\n",
    "        sum2 = sum2 + (y_train[i]**2)\n",
    "    k2 = sum1/sum2\n",
    "    y_pred1_1, y_train1_1 = [], []\n",
    "    for i in range(len(y_train)):\n",
    "        y_pred1_1.append(y_pred1[i]*k1)\n",
    "    for i in range(len(y_train)):\n",
    "        y_train1_1.append(y_train[i]*k2)\n",
    "    num, den = 0, 0\n",
    "    for i in range(len(y_train)):\n",
    "        num = num + ((y_pred1[i] - y_train1_1[i])**2)\n",
    "        den = den + ((y_pred1[i] - av_ytp)**2)\n",
    "    r2 = 1 - (num/den)\n",
    "    num, den = 0, 0\n",
    "    for i in range(len(y_train)):\n",
    "        num = num + ((y_train[i] - y_pred1_1[i])**2)\n",
    "        den = den + ((y_train[i] - av_yta)**2)\n",
    "    r2_ = 1 - (num/den)\n",
    "    \n",
    "    c1 = r2_score(y_train, y_pred1)\n",
    "    c2 = Q2f1(y_test, y_pred2, y_train)\n",
    "    c3 = (c1 - r2)/c1 \n",
    "    c4 = k1\n",
    "    c5 = np.abs(c1-r2_)\n",
    "    \n",
    "    if c1 >0.5 and c2 > 0.6 and c3 < 0.1 and c4 >= 0.85 and c4 <= 1.15 and c5 < 0.3:\n",
    "        val = 'PASS'\n",
    "        \n",
    "    else:\n",
    "        val = 'FAIL'\n",
    "        \n",
    "    return val\n",
    "    \n",
    "def SEE(y_train, y_pred1,dn):\n",
    "    y_train = list(y_train)\n",
    "    sum = 0\n",
    "    for i in range(len(y_train)):\n",
    "        sum = sum + ((y_train[i] - y_pred1[i])**2)\n",
    "    \n",
    "    n = len(y_train)-dn-1\n",
    "    \n",
    "    sa = np.sqrt(sum/n)\n",
    "    print(\"Model Standard Error of Estmation (Training) : \",round(sa,3))\n",
    "\n",
    "def get_model_summary(model):\n",
    "    stream = io.StringIO()\n",
    "    model.summary(print_fn=lambda x: stream.write(x + '\\n'))\n",
    "    summary_string = stream.getvalue()\n",
    "    stream.close()\n",
    "    return summary_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the file stem (ss/mm) ss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(964, 678) (302, 678) (241, 678)\n"
     ]
    }
   ],
   "source": [
    "## dataset\n",
    "dt = pd.read_csv(\"final_descp.csv\")\n",
    "X1 =  dt.iloc[:,2:]\n",
    "#y1 = dt[:]['2IC50'].apply(lambda x: x*(1/1000000000))\n",
    "y = np.log(dt[:]['2IC50'])\n",
    "\n",
    "\n",
    "stem = input(\"Enter the file stem (ss/mm)\")\n",
    "\n",
    "if stem == 'ss':\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scale = StandardScaler()\n",
    "    head = X1.columns\n",
    "    v = scale.fit_transform(X1)\n",
    "    X = pd.DataFrame(v,columns = head )\n",
    "    \n",
    "elif stem == 'mm':\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scale = MinMaxScaler()\n",
    "    head = X1.columns\n",
    "    v = scale.fit_transform(X1)\n",
    "    X = pd.DataFrame(v,columns = head )\n",
    "else:\n",
    "    X = X1\n",
    "\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split( X, y, test_size=0.2)#, random_state = 23)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X_tr, y_tr, test_size=0.2)#, random_state = 23)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the project name reg_nn_\n"
     ]
    }
   ],
   "source": [
    "log_name = str(input('Enter the project name'))+stem\n",
    "try:\n",
    "    shutil.rmtree(log_name+str('_log'))\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    shutil.rmtree(log_name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "def build_model(hp):\n",
    "    activation1=hp.Choice('Activation_functions', ['relu'])#, elu', 'tanh', 'sigmoid'])\n",
    "    batch_size = hp.Int('batch_size', 16, 32, step=16)\n",
    "    loss1 = hp.Choice('loss', ['mean_squared_error', 'huber_loss'])\n",
    "    #metrics1 =  hp.Choice('metrics', ['mean_squared_error', 'huber_loss'])\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(units=X.shape[1], input_shape=(X.shape[1],)))      \n",
    "    for i in range(hp.Int('num_layers', 1, 30, step = 1)):\n",
    "              model.add(layers.Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=1024, step=16 , default=0), activation=activation1))\n",
    "            \n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer = hp.Choice('Optimzer', ['SGD', 'RMSprop', 'Adagrad', 'Adam', 'Adamax']),\\\n",
    "        loss=loss1,\\\n",
    "        metrics='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mean_squared_error',\n",
    "    max_trials=25,\n",
    "    executions_per_trial=1,\n",
    "    directory=log_name,\n",
    "    project_name=log_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 Complete [00h 02m 46s]\n",
      "val_mean_squared_error: 3.353527545928955\n",
      "\n",
      "Best val_mean_squared_error So Far: 3.0773792266845703\n",
      "Total elapsed time: 01h 09m 05s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Sun Feb 14 18:06:12 2021\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "time1 = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = f\"{log_name}_log/{time1}\"\n",
    "tensorboard = TensorBoard(log_dir=logdir) # added\n",
    "callback1 = tf.keras.callbacks.EarlyStopping(monitor='mean_squared_error', patience=20)\n",
    "tuner.search(X_train, y_train, validation_data=(X_test, y_test), epochs = 250 ,callbacks=[tensorboard, callback1])    \n",
    "print(time.ctime())      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3458324]\n",
      "[0.3455692]\n",
      "[0.3458324]\n",
      "INFO:tensorflow:Assets written to: model_0_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                            | 1/25 [03:54<1:33:38, 234.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41208833]\n",
      "[0.4118517]\n",
      "[0.41208833]\n",
      "INFO:tensorflow:Assets written to: model_1_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▍                                                                         | 2/25 [08:39<1:35:39, 249.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00022602]\n",
      "[-0.00062859]\n",
      "[-0.00022602]\n",
      "INFO:tensorflow:Assets written to: model_2_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▌                                                                      | 3/25 [09:43<1:11:06, 193.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23881751]\n",
      "[0.23851115]\n",
      "[0.23881751]\n",
      "INFO:tensorflow:Assets written to: model_3_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▊                                                                   | 4/25 [16:54<1:32:46, 265.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4997307]\n",
      "[0.49952936]\n",
      "[0.4997307]\n",
      "INFO:tensorflow:Assets written to: model_4_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████                                                                | 5/25 [18:14<1:09:47, 209.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.491328]\n",
      "[0.49112326]\n",
      "[0.491328]\n",
      "INFO:tensorflow:Assets written to: model_5_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████▋                                                              | 6/25 [18:59<50:41, 160.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38295734]\n",
      "[0.38270897]\n",
      "[0.38295734]\n",
      "INFO:tensorflow:Assets written to: model_6_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▉                                                           | 7/25 [21:09<45:22, 151.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47950387]\n",
      "[0.47929436]\n",
      "[0.47950387]\n",
      "INFO:tensorflow:Assets written to: model_7_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████▏                                                       | 8/25 [24:33<47:19, 167.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30855888]\n",
      "[0.30828065]\n",
      "[0.30855888]\n",
      "INFO:tensorflow:Assets written to: model_8_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████▌                                                    | 9/25 [25:34<36:03, 135.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24588227]\n",
      "[0.24557877]\n",
      "[0.24588227]\n",
      "INFO:tensorflow:Assets written to: model_9_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████▍                                                | 10/25 [29:17<40:20, 161.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4844129]\n",
      "[0.48420537]\n",
      "[0.4844129]\n",
      "INFO:tensorflow:Assets written to: model_10_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████▋                                             | 11/25 [30:58<33:26, 143.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38738012]\n",
      "[0.3871336]\n",
      "[0.38738012]\n",
      "INFO:tensorflow:Assets written to: model_11_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████▉                                          | 12/25 [36:40<43:57, 202.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4347883]\n",
      "[0.43456078]\n",
      "[0.4347883]\n",
      "INFO:tensorflow:Assets written to: model_12_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████                                       | 13/25 [39:58<40:17, 201.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44284856]\n",
      "[0.44262433]\n",
      "[0.44284856]\n",
      "INFO:tensorflow:Assets written to: model_13_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████████████████▎                                   | 14/25 [42:26<34:00, 185.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3572299]\n",
      "[0.3569712]\n",
      "[0.3572299]\n",
      "INFO:tensorflow:Assets written to: model_14_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████▌                                | 15/25 [42:44<22:32, 135.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37652892]\n",
      "[0.37627798]\n",
      "[0.37652892]\n",
      "INFO:tensorflow:Assets written to: model_15_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████████████▍                             | 16/25 [43:00<14:54, 99.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3382842]\n",
      "[0.33801788]\n",
      "[0.3382842]\n",
      "INFO:tensorflow:Assets written to: model_16_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████▊                          | 17/25 [44:14<12:13, 91.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45492297]\n",
      "[0.45470363]\n",
      "[0.45492297]\n",
      "INFO:tensorflow:Assets written to: model_17_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████                       | 18/25 [45:17<09:41, 83.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32547164]\n",
      "[0.3252002]\n",
      "[0.32547164]\n",
      "INFO:tensorflow:Assets written to: model_18_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████████████████████████████████████████▎                   | 19/25 [47:24<09:37, 96.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42253196]\n",
      "[0.42229956]\n",
      "[0.42253196]\n",
      "INFO:tensorflow:Assets written to: model_19_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████▊                | 20/25 [54:20<16:00, 192.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42610902]\n",
      "[0.42587805]\n",
      "[0.42610902]\n",
      "INFO:tensorflow:Assets written to: model_20_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████████             | 21/25 [59:51<15:36, 234.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.395388]\n",
      "[0.3951447]\n",
      "[0.395388]\n",
      "INFO:tensorflow:Assets written to: model_21_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████████████████████████████████████████████████████▌         | 22/25 [1:01:39<09:48, 196.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05926871]\n",
      "[-0.05969501]\n",
      "[-0.05926871]\n",
      "INFO:tensorflow:Assets written to: model_22_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|████████████████████████████████████████████████████████████████████████▋      | 23/25 [1:01:48<04:39, 139.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7588097]\n",
      "[-0.75951755]\n",
      "[-0.7588097]\n",
      "INFO:tensorflow:Assets written to: model_23_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|███████████████████████████████████████████████████████████████████████████▊   | 24/25 [1:02:27<01:49, 109.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7490.665]\n",
      "[-7493.68]\n",
      "[-7490.665]\n",
      "INFO:tensorflow:Assets written to: model_24_ss.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 25/25 [1:04:04<00:00, 153.77s/it]\n"
     ]
    }
   ],
   "source": [
    "dt_tt = pd.DataFrame()\n",
    "callback1 = tf.keras.callbacks.EarlyStopping(monitor='mean_squared_error', patience=20)\n",
    "for i in tqdm(range(25)):\n",
    "    string = f'model_{i}_{stem}'\n",
    "    best_hp = tuner.get_best_hyperparameters(num_trials=25)[i]\n",
    "    model = build_model(best_hp)\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = 250, verbose = 0, callbacks = callback1)\n",
    "    # Predicting the Test set results\n",
    "    y_pred1 = model.predict(X_train)\n",
    "    y_pred2 = model.predict(X_val)\n",
    "    \n",
    "    try:\n",
    "        model_summary_string = get_model_summary(model)\n",
    "        out = open(string + '.txt','w')\n",
    "        out.write(model_summary_string)\n",
    "        out.close\n",
    "\n",
    "\n",
    "        mse2 = round(mean_squared_error(y_val, y_pred2),3)\n",
    "        mse1 = round(mean_squared_error(y_train, y_pred1),3)\n",
    "        mae2 = round(mean_absolute_error(y_val, y_pred2),3)\n",
    "        mae1 = round(mean_absolute_error(y_train, y_pred1),3)\n",
    "        cod = round(r2_score(y_train, y_pred1),3)\n",
    "        q2f1 = round(Q2f1(y_val, y_pred2, y_train),3)\n",
    "        q2f2 = round(Q2f2(y_val, y_pred2),3)\n",
    "        maec = maecr(y_val, y_pred2, y_train)\n",
    "        maec95 = maecr_95(y_val, y_pred2, y_train)\n",
    "        trop = tropsha(y_train, y_val, y_pred1, y_pred2)\n",
    "\n",
    "        dt_tt = dt_tt.append({'model' : 'model_'+str(i),\\\n",
    "                              'Activation_functions' : best_hp.get('Activation_functions'),\\\n",
    "                              'Optimzer' : best_hp.get('Optimzer'),\\\n",
    "                                'loss' : best_hp.get('loss'),\\\n",
    "                             'batch_size': best_hp.get('batch_size'),\\\n",
    "                             'num_layers' : best_hp.get('num_layers'),\\\n",
    "                             'MSE Train' : mse1, 'MSE Test' : mse2, \\\n",
    "                             'MAE Train ' : mae1, 'MAE Test' : mae2, \\\n",
    "                             'Coefficient of determination(train)': cod,\\\n",
    "                             'Q2f1' : q2f1, 'Q2f2' : q2f2,\\\n",
    "                             'MAE criteria' : maec, \\\n",
    "                            'MAE criteria (95%)' : maec95, \\\n",
    "                             'TROPSA criteria' : trop},\\\n",
    "                            ignore_index = True)\n",
    "    \n",
    "        model.save(string+str('.tf'),overwrite=True)\n",
    "        \n",
    "    except:\n",
    "        print(string, 'failed to generate')\n",
    "        strr = string+str('.tf')+\" failed to generate.\"\n",
    "        out = open(string + '.txt','w')\n",
    "        out.write(strr)\n",
    "        out.close\n",
    "        \n",
    "        try: \n",
    "            shutil.rmtree(string+str('.tf'))\n",
    "        except:\n",
    "            pass\n",
    "         \n",
    "dt_tt.to_csv(log_name+stem+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''from ann_visualizer.visualize import ann_viz\n",
    "model = tf.keras.models.load_model('model_1.tf')\n",
    "ann_viz(model, view=True, filename='network.gv', title='MyNeural Network')'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
