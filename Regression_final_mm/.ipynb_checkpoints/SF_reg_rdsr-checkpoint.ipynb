{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression model\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "#modules\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.layers import Dense, Activation, Embedding, Flatten, LeakyReLU, BatchNormalization, Dropout\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os, random, shutil, logging, datetime, pickle,io, winsound, joblib\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Linear regression model\")\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "try:\n",
    "    #Disable all GPUS\n",
    "    tf.config.set_visible_devices([], 'GPU'),\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        assert device.device_type != 'GPU'\n",
    "except:\n",
    "    #Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q2f1(y_test, y_pred2, y_train):\n",
    "    '''R2 for test set or Q2f1'''\n",
    "    mean_y_train = np.mean(y_train)\n",
    "    num, den = 0, 0\n",
    "    y_test = list(y_test)\n",
    "    for i in range(len(y_test)):\n",
    "        num = num + ((y_test[i] - y_pred2[i])**2)\n",
    "        den = den + ((y_test[i] - mean_y_train)**2)\n",
    "    r2test = (1 -(num/den))\n",
    "    print(r2test)\n",
    "    return r2test[0]\n",
    "\n",
    "def Q2f2(y_test, y_pred2):\n",
    "    '''R2 for test set or Q2f2'''\n",
    "    mean_y_test = np.mean(y_test)\n",
    "    num, den = 0, 0\n",
    "    y_test = list(y_test)\n",
    "    for i in range(len(y_test)):\n",
    "        num = num + ((y_test[i] - y_pred2[i])**2)\n",
    "        den = den + ((y_test[i] - mean_y_test)**2)\n",
    "    r2test = (1 -(num/den))\n",
    "    print(r2test)\n",
    "    return r2test[0]\n",
    "\n",
    "    \n",
    "def maecr(y_test, y_pred2, y_train):\n",
    "    y_test = list(y_test)\n",
    "    \n",
    "    min1 = y_train.min()\n",
    "    max1 = y_train.max()\n",
    "    rang = max1-min1\n",
    "    \n",
    "    n = len(y_test)\n",
    "    m = len(y_pred2)\n",
    "    ma, sd = 0,0\n",
    "    for i, j in zip(range(n),range(m)):\n",
    "        ma = ma + np.abs(y_test[i] - y_pred2[j])\n",
    "        \n",
    "    mae = ma/n\n",
    "    \n",
    "    for i, j in zip(range(n),range(m)):\n",
    "        sd = sd + ((np.abs(y_test[i] - y_pred2[j])-mae)**2)\n",
    "    \n",
    "    sd1 = np.sqrt(sd/n)\n",
    "         \n",
    "    if (mae <= (0.1*rang)) and ((mae+(3*sd1)) <= (0.2*rang)):\n",
    "        val = 'GOOD'\n",
    "        \n",
    "    elif (mae > (0.15*rang)) or ((mae+(3*sd1)) > (0.25*rang)): \n",
    "        val = 'BAD'\n",
    "        \n",
    "    else:\n",
    "        val = 'MODERATE'\n",
    "        \n",
    "    return val\n",
    "\n",
    "def maecr_95(y_test, y_pred2, y_train):\n",
    "    y_test1 = pd.DataFrame()\n",
    "    for i in y_test.index:\n",
    "        y_test1 = y_test1.append({'activity' : y_test[i]}, ignore_index = True)\n",
    "    \n",
    "    y_pred2_df = pd.DataFrame()\n",
    "    for i in range(len(y_pred2)):\n",
    "        y_pred2_df = y_pred2_df.append({'activity' : y_pred2[i]}, ignore_index = True)\n",
    "        \n",
    "    print(y_pred2_df.index,y_test1.index)   \n",
    "    \n",
    "    min1 = y_train.min()\n",
    "    max1 = y_train.max()\n",
    "    rang = max1-min1\n",
    "    \n",
    "    n = len(y_test)\n",
    "    ma, sd = 0,0\n",
    "    m1 =  int(0.05*n)\n",
    "    df_abs = pd.DataFrame()\n",
    "    \n",
    "    for i in range(n):\n",
    "        df_abs = df_abs.append({'Absolute_error': float(np.abs(y_test1.iloc[i,0] - y_pred2_df.iloc[i,0]))},ignore_index=True)\n",
    "    print(df_abs)   \n",
    "    index = df_abs.nlargest(m1,'Absolute_error').index\n",
    "    \n",
    "    y_test1 = y_test1.drop(axis=0, index=index)\n",
    "    y_pred2_df = y_pred2_df.drop(axis=0, index=index)\n",
    "    index1 = y_pred2_df.index\n",
    "   \n",
    "    n = len(index1)\n",
    "    for i in index1:\n",
    "        ma = ma + np.abs(y_test1['activity'].loc[i] - y_pred2_df['activity'].loc[i])\n",
    "        #print(ma)\n",
    "        \n",
    "    mae = ma/n\n",
    "    \n",
    "    for i in index1:\n",
    "        sd = sd + ((np.abs(y_test1['activity'].loc[i] - y_pred2_df['activity'].loc[i])-mae)**2)\n",
    "    \n",
    "    sd1 = np.sqrt(sd/n)\n",
    "         \n",
    "    if (mae <= (0.1*rang)) and ((mae+(3*sd1)) <= (0.2*rang)):\n",
    "        val = 'GOOD'\n",
    "        print(mae, 0.1*rang, mae+(3*sd1),0.2*rang)\n",
    "    elif (mae > (0.15*rang)) or ((mae+(3*sd1)) > (0.25*rang)): \n",
    "        val = 'BAD'\n",
    "        print(mae, 0.15*rang, mae+(3*sd1), 0.25*rang)\n",
    "    else:\n",
    "        val = 'MODERATE'\n",
    "        \n",
    "    return val\n",
    "\n",
    "def tropsha(y_train, y_test, y_pred1, y_pred2):\n",
    "    r2_score(y_train, y_pred1)\n",
    "    av_yta = np.mean(y_test)\n",
    "    av_ytp = np.mean(y_pred1)\n",
    "    k1, k2 = 0, 0\n",
    "    y_train = list(y_train)\n",
    "    y_pred1 = list(y_pred1)\n",
    "    sum1, sum2 = 0,0\n",
    "    for i in range(len(y_train)):\n",
    "        sum1 = sum1 + (y_train[i]*y_pred1[i])\n",
    "        sum2 = sum2 + (y_pred1[i]**2)\n",
    "    k1 = sum1/sum2\n",
    "    sum1, sum2 = 0,0\n",
    "    for i in range(len(y_train)):\n",
    "        sum1 = sum1 + (y_train[i]*y_pred1[i])\n",
    "        sum2 = sum2 + (y_train[i]**2)\n",
    "    k2 = sum1/sum2\n",
    "    y_pred1_1, y_train1_1 = [], []\n",
    "    for i in range(len(y_train)):\n",
    "        y_pred1_1.append(y_pred1[i]*k1)\n",
    "    for i in range(len(y_train)):\n",
    "        y_train1_1.append(y_train[i]*k2)\n",
    "    num, den = 0, 0\n",
    "    for i in range(len(y_train)):\n",
    "        num = num + ((y_pred1[i] - y_train1_1[i])**2)\n",
    "        den = den + ((y_pred1[i] - av_ytp)**2)\n",
    "    r2 = 1 - (num/den)\n",
    "    num, den = 0, 0\n",
    "    for i in range(len(y_train)):\n",
    "        num = num + ((y_train[i] - y_pred1_1[i])**2)\n",
    "        den = den + ((y_train[i] - av_yta)**2)\n",
    "    r2_ = 1 - (num/den)\n",
    "    \n",
    "    c1 = r2_score(y_train, y_pred1)\n",
    "    c2 = Q2f1(y_test, y_pred2, y_train)\n",
    "    c3 = (c1 - r2)/c1 \n",
    "    c4 = k1\n",
    "    c5 = np.abs(c1-r2_)\n",
    "    \n",
    "    if c1 >0.5 and c2 > 0.6 and c3 < 0.1 and c4 >= 0.85 and c4 <= 1.15 and c5 < 0.3:\n",
    "        val = 'PASS'\n",
    "        \n",
    "    else:\n",
    "        val = 'FAIL'\n",
    "        \n",
    "    return val\n",
    "    \n",
    "def SEE(y_train, y_pred1,dn):\n",
    "    y_train = list(y_train)\n",
    "    sum = 0\n",
    "    for i in range(len(y_train)):\n",
    "        sum = sum + ((y_train[i] - y_pred1[i])**2)\n",
    "    \n",
    "    n = len(y_train)-dn-1\n",
    "    \n",
    "    sa = np.sqrt(sum/n)\n",
    "    print(\"Model Standard Error of Estmation (Training) : \",round(sa,3))\n",
    "\n",
    "def get_model_summary(model):\n",
    "    stream = io.StringIO()\n",
    "    model.summary(print_fn=lambda x: stream.write(x + '\\n'))\n",
    "    summary_string = stream.getvalue()\n",
    "    stream.close()\n",
    "    return summary_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the file stem (ss/mm) ss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(964, 678) (302, 678) (241, 678)\n"
     ]
    }
   ],
   "source": [
    "## dataset\n",
    "dt = pd.read_csv(\"final_descp.csv\")\n",
    "X1 =  dt.iloc[:,2:]\n",
    "#y1 = dt[:]['2IC50'].apply(lambda x: x*(1/1000000000))\n",
    "y = np.log(dt[:]['2IC50'])\n",
    "\n",
    "\n",
    "stem = input(\"Enter the file stem (ss/mm)\")\n",
    "\n",
    "if stem == 'ss':\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scale = StandardScaler()\n",
    "    head = X1.columns\n",
    "    v = scale.fit_transform(X1)\n",
    "    X = pd.DataFrame(v,columns = head )\n",
    "    \n",
    "elif stem == 'mm':\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scale = MinMaxScaler()\n",
    "    head = X1.columns\n",
    "    v = scale.fit_transform(X1)\n",
    "    X = pd.DataFrame(v,columns = head )\n",
    "else:\n",
    "    X = X1\n",
    "\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split( X, y, test_size=0.2)#, random_state = 23)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X_tr, y_tr, test_size=0.2)#, random_state = 23)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the project name Nuenet_reg_\n"
     ]
    }
   ],
   "source": [
    "log_name = str(input('Enter the project name'))+stem\n",
    "try:\n",
    "    shutil.rmtree(log_name+str('_log'))\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    shutil.rmtree(log_name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "def build_model(hp):\n",
    "    activation1=hp.Choice('Activation_functions', ['relu'])#, elu', 'tanh', 'sigmoid'])\n",
    "    batch_size = hp.Int('batch_size', 16, 32, step=16)\n",
    "    loss1 = hp.Choice('loss', ['mean_squared_error', 'huber_loss'])\n",
    "    #metrics1 =  hp.Choice('metrics', ['mean_squared_error', 'huber_loss'])\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(units=X.shape[1], input_shape=(X.shape[1],)))      \n",
    "    for i in range(hp.Int('num_layers', 1, 30, step = 1)):\n",
    "              model.add(layers.Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=1024, step=16 , default=0), activation=activation1))\n",
    "            \n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer = hp.Choice('Optimzer', ['SGD', 'RMSprop', 'Adagrad', 'Adam', 'Adamax']),\\\n",
    "        loss=loss1,\\\n",
    "        metrics='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mean_squared_error',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory=log_name,\n",
    "    project_name=log_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 12s]\n",
      "val_mean_squared_error: nan\n",
      "\n",
      "Best val_mean_squared_error So Far: 3.8086798191070557\n",
      "Total elapsed time: 00h 08m 36s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Sun Feb 14 16:26:18 2021\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "time1 = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = f\"{log_name}_log/{time1}\"\n",
    "tensorboard = TensorBoard(log_dir=logdir) # added\n",
    "callback1 = tf.keras.callbacks.EarlyStopping(monitor='mean_squared_error', patience=20)\n",
    "tuner.search(X_train, y_train, validation_data=(X_test, y_test), epochs = 250 ,callbacks=[tensorboard, callback1])    \n",
    "print(time.ctime())      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=302, step=1) RangeIndex(start=0, stop=302, step=1)\n",
      "     Absolute_error\n",
      "0          0.949668\n",
      "1          0.347218\n",
      "2          0.654846\n",
      "3          1.086493\n",
      "4          1.103405\n",
      "..              ...\n",
      "297        0.079313\n",
      "298        1.978958\n",
      "299        1.779029\n",
      "300        1.587595\n",
      "301        1.295782\n",
      "\n",
      "[302 rows x 1 columns]\n",
      "[1.6140715] 2.390366114124655 [5.201994] 3.9839435235410914\n",
      "INFO:tensorflow:Assets written to: model_0_ss.tf\\assets\n",
      "RangeIndex(start=0, stop=302, step=1) RangeIndex(start=0, stop=302, step=1)\n",
      "     Absolute_error\n",
      "0          0.712990\n",
      "1          1.624590\n",
      "2          0.752986\n",
      "3          0.288545\n",
      "4          0.297115\n",
      "..              ...\n",
      "297        2.040056\n",
      "298        0.558217\n",
      "299        1.720786\n",
      "300        2.879343\n",
      "301        0.637448\n",
      "\n",
      "[302 rows x 1 columns]\n",
      "[1.3623204] 2.390366114124655 [4.4640875] 3.9839435235410914\n",
      "INFO:tensorflow:Assets written to: model_1_ss.tf\\assets\n",
      "RangeIndex(start=0, stop=302, step=1) RangeIndex(start=0, stop=302, step=1)\n",
      "     Absolute_error\n",
      "0          3.100183\n",
      "1          8.392789\n",
      "2          5.829111\n",
      "3          4.714672\n",
      "4          4.883469\n",
      "..              ...\n",
      "297        4.053745\n",
      "298        5.093763\n",
      "299        1.217308\n",
      "300        6.380428\n",
      "301        5.072857\n",
      "\n",
      "[302 rows x 1 columns]\n",
      "[5.464336] 2.390366114124655 [12.552121] 3.9839435235410914\n",
      "INFO:tensorflow:Assets written to: model_2_ss.tf\\assets\n",
      "RangeIndex(start=0, stop=302, step=1) RangeIndex(start=0, stop=302, step=1)\n",
      "     Absolute_error\n",
      "0          4.320002\n",
      "1          9.612607\n",
      "2          7.048930\n",
      "3          5.934490\n",
      "4          6.103287\n",
      "..              ...\n",
      "297        5.273564\n",
      "298        6.313582\n",
      "299        2.437126\n",
      "300        7.600246\n",
      "301        6.292675\n",
      "\n",
      "[302 rows x 1 columns]\n",
      "[6.6719794] 2.390366114124655 [13.830269] 3.9839435235410914\n",
      "INFO:tensorflow:Assets written to: model_3_ss.tf\\assets\n",
      "RangeIndex(start=0, stop=302, step=1) RangeIndex(start=0, stop=302, step=1)\n",
      "     Absolute_error\n",
      "0          0.042908\n",
      "1          2.463418\n",
      "2          0.328042\n",
      "3          0.054420\n",
      "4          1.421700\n",
      "..              ...\n",
      "297        1.956263\n",
      "298        0.692227\n",
      "299        2.740631\n",
      "300        0.667434\n",
      "301        1.228540\n",
      "\n",
      "[302 rows x 1 columns]\n",
      "[1.3771333] 2.390366114124655 [4.577616] 3.9839435235410914\n",
      "INFO:tensorflow:Assets written to: model_4_ss.tf\\assets\n"
     ]
    }
   ],
   "source": [
    "dt_tt = pd.DataFrame()\n",
    "callback1 = tf.keras.callbacks.EarlyStopping(monitor='mean_squared_error', patience=20)\n",
    "for i in tqdn(range(5)):\n",
    "    string = f'model_{i}_{stem}'\n",
    "    best_hp = tuner.get_best_hyperparameters(num_trials=5)[i]\n",
    "    model = build_model(best_hp)\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = 250, verbose = 0, callbacks = callback1)\n",
    "    # Predicting the Test set results\n",
    "    y_pred1 = model.predict(X_train)\n",
    "    y_pred2 = model.predict(X_val)\n",
    "    \n",
    "    try:\n",
    "        model_summary_string = get_model_summary(model)\n",
    "        out = open(string + '.txt','w')\n",
    "        out.write(model_summary_string)\n",
    "        out.close\n",
    "\n",
    "\n",
    "        mse2 = round(mean_squared_error(y_val, y_pred2),3)\n",
    "        mse1 = round(mean_squared_error(y_train, y_pred1),3)\n",
    "        mae2 = round(mean_absolute_error(y_val, y_pred2),3)\n",
    "        mae1 = round(mean_absolute_error(y_train, y_pred1),3)\n",
    "        cod = round(r2_score(y_train, y_pred1),3)\n",
    "        q2f1 = round(Q2f1(y_val, y_pred2, y_train),3)\n",
    "        q2f2 = round(Q2f2(y_val, y_pred2),3)\n",
    "        maec = maecr(y_val, y_pred2, y_train)\n",
    "        maec95 = maecr_95(y_val, y_pred2, y_train)\n",
    "        trop = tropsha(y_train, y_val, y_pred1, y_pred2)\n",
    "\n",
    "        dt_tt = dt_tt.append({'model' : 'model_'+str(i),\\\n",
    "                              'Activation_functions' : best_hp.get('Activation_functions'),\\\n",
    "                              'Optimzer' : best_hp.get('Optimzer'),\\\n",
    "                                'loss' : best_hp.get('loss'),\\\n",
    "                             'batch_size': best_hp.get('batch_size'),\\\n",
    "                             'num_layers' : best_hp.get('num_layers'),\\\n",
    "                             'MSE Train' : mse1, 'MSE Test' : mse2, \\\n",
    "                             'MAE Train ' : mae1, 'MAE Test' : mae2, \\\n",
    "                             'Coefficient of determination(train)': cod,\\\n",
    "                             'Q2f1' : q2f1, 'Q2f2' : q2f2,\\\n",
    "                             'MAE criteria' : maec, \\\n",
    "                            'MAE criteria (95%)' : maec95, \\\n",
    "                             'TROPSA criteria' : trop},\\\n",
    "                            ignore_index = True)\n",
    "    \n",
    "        model.save(string+str('.tf'),overwrite=True)\n",
    "        \n",
    "    except:\n",
    "        print(string, 'failed to generate')\n",
    "        strr = string+str('.tf')+\" failed to generate.\"\n",
    "        out = open(string + '.txt','w')\n",
    "        out.write(strr)\n",
    "        out.close\n",
    "        \n",
    "        try: \n",
    "            shutil.rmtree(string+str('.tf'))\n",
    "        except:\n",
    "            pass\n",
    "         \n",
    "dt_tt.to_csv(log_name+stem+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''from ann_visualizer.visualize import ann_viz\n",
    "model = tf.keras.models.load_model('model_1.tf')\n",
    "ann_viz(model, view=True, filename='network.gv', title='MyNeural Network')'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
