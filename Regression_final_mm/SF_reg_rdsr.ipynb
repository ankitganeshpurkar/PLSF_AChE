{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression model\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "#modules\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.layers import Dense, Activation, Embedding, Flatten, LeakyReLU, BatchNormalization, Dropout\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os, random, shutil, logging, datetime, pickle,io, winsound, joblib\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Linear regression model\")\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "try:\n",
    "    #Disable all GPUS\n",
    "    tf.config.set_visible_devices([], 'GPU'),\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        assert device.device_type != 'GPU'\n",
    "except:\n",
    "    #Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q2f1(y_test, y_pred2, y_train):\n",
    "    '''R2 for test set or Q2f1'''\n",
    "    mean_y_train = np.mean(y_train)\n",
    "    num, den = 0, 0\n",
    "    y_test = list(y_test)\n",
    "    for i in range(len(y_test)):\n",
    "        num = num + ((y_test[i] - y_pred2[i])**2)\n",
    "        den = den + ((y_test[i] - mean_y_train)**2)\n",
    "    r2test = (1 -(num/den))\n",
    "    print(r2test)\n",
    "    return r2test[0]\n",
    "\n",
    "def Q2f2(y_test, y_pred2):\n",
    "    '''R2 for test set or Q2f2'''\n",
    "    mean_y_test = np.mean(y_test)\n",
    "    num, den = 0, 0\n",
    "    y_test = list(y_test)\n",
    "    for i in range(len(y_test)):\n",
    "        num = num + ((y_test[i] - y_pred2[i])**2)\n",
    "        den = den + ((y_test[i] - mean_y_test)**2)\n",
    "    r2test = (1 -(num/den))\n",
    "    print(r2test)\n",
    "    return r2test[0]\n",
    "\n",
    "    \n",
    "def maecr(y_test, y_pred2, y_train):\n",
    "    y_test = list(y_test)\n",
    "    \n",
    "    min1 = y_train.min()\n",
    "    max1 = y_train.max()\n",
    "    rang = max1-min1\n",
    "    \n",
    "    n = len(y_test)\n",
    "    m = len(y_pred2)\n",
    "    ma, sd = 0,0\n",
    "    for i, j in zip(range(n),range(m)):\n",
    "        ma = ma + np.abs(y_test[i] - y_pred2[j])\n",
    "        \n",
    "    mae = ma/n\n",
    "    \n",
    "    for i, j in zip(range(n),range(m)):\n",
    "        sd = sd + ((np.abs(y_test[i] - y_pred2[j])-mae)**2)\n",
    "    \n",
    "    sd1 = np.sqrt(sd/n)\n",
    "         \n",
    "    if (mae <= (0.1*rang)) and ((mae+(3*sd1)) <= (0.2*rang)):\n",
    "        val = 'GOOD'\n",
    "        \n",
    "    elif (mae > (0.15*rang)) or ((mae+(3*sd1)) > (0.25*rang)): \n",
    "        val = 'BAD'\n",
    "        \n",
    "    else:\n",
    "        val = 'MODERATE'\n",
    "        \n",
    "    return val\n",
    "\n",
    "def maecr_95(y_test, y_pred2, y_train):\n",
    "    y_test1 = pd.DataFrame()\n",
    "    for i in y_test.index:\n",
    "        y_test1 = y_test1.append({'activity' : y_test[i]}, ignore_index = True)\n",
    "    \n",
    "    y_pred2_df = pd.DataFrame()\n",
    "    for i in range(len(y_pred2)):\n",
    "        y_pred2_df = y_pred2_df.append({'activity' : y_pred2[i]}, ignore_index = True)\n",
    "        \n",
    "    \n",
    "    \n",
    "    min1 = y_train.min()\n",
    "    max1 = y_train.max()\n",
    "    rang = max1-min1\n",
    "    \n",
    "    n = len(y_test)\n",
    "    ma, sd = 0,0\n",
    "    m1 =  int(0.05*n)\n",
    "    df_abs = pd.DataFrame()\n",
    "    \n",
    "    for i in range(n):\n",
    "        df_abs = df_abs.append({'Absolute_error': float(np.abs(y_test1.iloc[i,0] - y_pred2_df.iloc[i,0]))},ignore_index=True)\n",
    "    #print(df_abs)   \n",
    "    index = df_abs.nlargest(m1,'Absolute_error').index\n",
    "    \n",
    "    y_test1 = y_test1.drop(axis=0, index=index)\n",
    "    y_pred2_df = y_pred2_df.drop(axis=0, index=index)\n",
    "    index1 = y_pred2_df.index\n",
    "   \n",
    "    n = len(index1)\n",
    "    for i in index1:\n",
    "        ma = ma + np.abs(y_test1['activity'].loc[i] - y_pred2_df['activity'].loc[i])\n",
    "        #print(ma)\n",
    "        \n",
    "    mae = ma/n\n",
    "    \n",
    "    for i in index1:\n",
    "        sd = sd + ((np.abs(y_test1['activity'].loc[i] - y_pred2_df['activity'].loc[i])-mae)**2)\n",
    "    \n",
    "    sd1 = np.sqrt(sd/n)\n",
    "         \n",
    "    if (mae <= (0.1*rang)) and ((mae+(3*sd1)) <= (0.2*rang)):\n",
    "        val = 'GOOD'\n",
    "        #print(mae, 0.1*rang, mae+(3*sd1),0.2*rang)\n",
    "    elif (mae > (0.15*rang)) or ((mae+(3*sd1)) > (0.25*rang)): \n",
    "        val = 'BAD'\n",
    "        #print(mae, 0.15*rang, mae+(3*sd1), 0.25*rang)\n",
    "    else:\n",
    "        val = 'MODERATE'\n",
    "        \n",
    "    return val\n",
    "\n",
    "def tropsha(y_train, y_test, y_pred1, y_pred2):\n",
    "    r2_score(y_train, y_pred1)\n",
    "    av_yta = np.mean(y_test)\n",
    "    av_ytp = np.mean(y_pred1)\n",
    "    k1, k2 = 0, 0\n",
    "    y_train = list(y_train)\n",
    "    y_pred1 = list(y_pred1)\n",
    "    sum1, sum2 = 0,0\n",
    "    for i in range(len(y_train)):\n",
    "        sum1 = sum1 + (y_train[i]*y_pred1[i])\n",
    "        sum2 = sum2 + (y_pred1[i]**2)\n",
    "    k1 = sum1/sum2\n",
    "    sum1, sum2 = 0,0\n",
    "    for i in range(len(y_train)):\n",
    "        sum1 = sum1 + (y_train[i]*y_pred1[i])\n",
    "        sum2 = sum2 + (y_train[i]**2)\n",
    "    k2 = sum1/sum2\n",
    "    y_pred1_1, y_train1_1 = [], []\n",
    "    for i in range(len(y_train)):\n",
    "        y_pred1_1.append(y_pred1[i]*k1)\n",
    "    for i in range(len(y_train)):\n",
    "        y_train1_1.append(y_train[i]*k2)\n",
    "    num, den = 0, 0\n",
    "    for i in range(len(y_train)):\n",
    "        num = num + ((y_pred1[i] - y_train1_1[i])**2)\n",
    "        den = den + ((y_pred1[i] - av_ytp)**2)\n",
    "    r2 = 1 - (num/den)\n",
    "    num, den = 0, 0\n",
    "    for i in range(len(y_train)):\n",
    "        num = num + ((y_train[i] - y_pred1_1[i])**2)\n",
    "        den = den + ((y_train[i] - av_yta)**2)\n",
    "    r2_ = 1 - (num/den)\n",
    "    \n",
    "    c1 = r2_score(y_train, y_pred1)\n",
    "    c2 = Q2f1(y_test, y_pred2, y_train)\n",
    "    c3 = (c1 - r2)/c1 \n",
    "    c4 = k1\n",
    "    c5 = np.abs(c1-r2_)\n",
    "    \n",
    "    if c1 >0.5 and c2 > 0.6 and c3 < 0.1 and c4 >= 0.85 and c4 <= 1.15 and c5 < 0.3:\n",
    "        val = 'PASS'\n",
    "        \n",
    "    else:\n",
    "        val = 'FAIL'\n",
    "        \n",
    "    return val\n",
    "    \n",
    "def SEE(y_train, y_pred1,dn):\n",
    "    y_train = list(y_train)\n",
    "    sum = 0\n",
    "    for i in range(len(y_train)):\n",
    "        sum = sum + ((y_train[i] - y_pred1[i])**2)\n",
    "    \n",
    "    n = len(y_train)-dn-1\n",
    "    \n",
    "    sa = np.sqrt(sum/n)\n",
    "    print(\"Model Standard Error of Estmation (Training) : \",round(sa,3))\n",
    "\n",
    "def get_model_summary(model):\n",
    "    stream = io.StringIO()\n",
    "    model.summary(print_fn=lambda x: stream.write(x + '\\n'))\n",
    "    summary_string = stream.getvalue()\n",
    "    stream.close()\n",
    "    return summary_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the file stem (ss/mm) mm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(964, 678) (302, 678) (241, 678)\n"
     ]
    }
   ],
   "source": [
    "## dataset\n",
    "dt = pd.read_csv(\"final_descp.csv\")\n",
    "X1 =  dt.iloc[:,2:]\n",
    "#y1 = dt[:]['2IC50'].apply(lambda x: x*(1/1000000000))\n",
    "y = np.log(dt[:]['2IC50'])\n",
    "\n",
    "\n",
    "stem = input(\"Enter the file stem (ss/mm)\")\n",
    "\n",
    "if stem == 'ss':\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scale = StandardScaler()\n",
    "    head = X1.columns\n",
    "    v = scale.fit_transform(X1)\n",
    "    X = pd.DataFrame(v,columns = head )\n",
    "    \n",
    "elif stem == 'mm':\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scale = MinMaxScaler()\n",
    "    head = X1.columns\n",
    "    v = scale.fit_transform(X1)\n",
    "    X = pd.DataFrame(v,columns = head )\n",
    "else:\n",
    "    X = X1\n",
    "\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split( X, y, test_size=0.2)#, random_state = 23)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X_tr, y_tr, test_size=0.2)#, random_state = 23)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the project name ReG_\n"
     ]
    }
   ],
   "source": [
    "log_name = str(input('Enter the project name'))+stem\n",
    "try:\n",
    "    shutil.rmtree(log_name+str('_log'))\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    shutil.rmtree(log_name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "def build_model(hp):\n",
    "    activation1=hp.Choice('Activation_functions', ['relu'])#, elu', 'tanh', 'sigmoid'])\n",
    "    batch_size = hp.Int('batch_size', 16, 32, step=16)\n",
    "    loss1 = hp.Choice('loss', ['mean_squared_error', 'huber_loss'])\n",
    "    #metrics1 =  hp.Choice('metrics', ['mean_squared_error', 'huber_loss'])\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(units=X.shape[1], input_shape=(X.shape[1],)))      \n",
    "    for i in range(hp.Int('num_layers', 1, 30, step = 1)):\n",
    "              model.add(layers.Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=1024, step=16 , default=0), activation=activation1))\n",
    "            \n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer = hp.Choice('Optimzer', ['SGD', 'RMSprop', 'Adagrad', 'Adam', 'Adamax']),\\\n",
    "        loss=loss1,\\\n",
    "        metrics='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mean_squared_error',\n",
    "    max_trials=25,\n",
    "    executions_per_trial=1,\n",
    "    directory=log_name,\n",
    "    project_name=log_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 Complete [00h 00m 28s]\n",
      "val_mean_squared_error: 6.845282077789307\n",
      "\n",
      "Best val_mean_squared_error So Far: 3.6254775524139404\n",
      "Total elapsed time: 00h 40m 14s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Sun Feb 14 18:15:34 2021\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "time1 = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = f\"{log_name}_log/{time1}\"\n",
    "tensorboard = TensorBoard(log_dir=logdir) # added\n",
    "callback1 = tf.keras.callbacks.EarlyStopping(monitor='mean_squared_error', patience=20)\n",
    "tuner.search(X_train, y_train, validation_data=(X_test, y_test), epochs = 250 ,callbacks=[tensorboard, callback1])    \n",
    "print(time.ctime())      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31610358]\n",
      "[0.31152397]\n",
      "[0.31610358]\n",
      "INFO:tensorflow:Assets written to: model_0_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                               | 1/25 [00:51<20:37, 51.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.14425218]\n",
      "[-0.15191448]\n",
      "[-0.14425218]\n",
      "INFO:tensorflow:Assets written to: model_1_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▋                                                                            | 2/25 [01:20<17:06, 44.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3444978]\n",
      "[0.3401084]\n",
      "[0.3444978]\n",
      "INFO:tensorflow:Assets written to: model_2_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▉                                                                         | 3/25 [01:39<13:37, 37.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34035492]\n",
      "[0.33593774]\n",
      "[0.34035492]\n",
      "INFO:tensorflow:Assets written to: model_3_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▎                                                                     | 4/25 [03:07<18:19, 52.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22192019]\n",
      "[0.21670997]\n",
      "[0.22192019]\n",
      "INFO:tensorflow:Assets written to: model_4_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 5/25 [04:36<21:07, 63.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35767514]\n",
      "[0.35337394]\n",
      "[0.35767514]\n",
      "INFO:tensorflow:Assets written to: model_5_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████▉                                                               | 6/25 [06:31<24:59, 78.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23102874]\n",
      "[0.22587949]\n",
      "[0.23102874]\n",
      "INFO:tensorflow:Assets written to: model_6_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████▏                                                           | 7/25 [07:19<20:50, 69.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3931827]\n",
      "[0.38911927]\n",
      "[0.3931827]\n",
      "INFO:tensorflow:Assets written to: model_7_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████▌                                                        | 8/25 [07:45<16:00, 56.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20174104]\n",
      "[0.19639564]\n",
      "[0.20174104]\n",
      "INFO:tensorflow:Assets written to: model_8_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████▉                                                     | 9/25 [09:13<17:34, 65.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30243158]\n",
      "[0.2977605]\n",
      "[0.30243158]\n",
      "INFO:tensorflow:Assets written to: model_9_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████▊                                                 | 10/25 [10:02<15:14, 60.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3347993]\n",
      "[0.33034492]\n",
      "[0.3347993]\n",
      "INFO:tensorflow:Assets written to: model_10_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████                                              | 11/25 [12:48<21:33, 92.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29409558]\n",
      "[0.28936863]\n",
      "[0.29409558]\n",
      "INFO:tensorflow:Assets written to: model_11_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████████████████████████▎                                          | 12/25 [13:39<17:18, 79.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06563818]\n",
      "[0.05938143]\n",
      "[0.06563818]\n",
      "INFO:tensorflow:Assets written to: model_12_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████▋                                       | 13/25 [14:44<15:05, 75.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2958967]\n",
      "[0.2911818]\n",
      "[0.2958967]\n",
      "INFO:tensorflow:Assets written to: model_13_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████████████████▉                                    | 14/25 [17:05<17:25, 95.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37991244]\n",
      "[0.37576014]\n",
      "[0.37991244]\n",
      "INFO:tensorflow:Assets written to: model_14_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▏                                | 15/25 [18:31<15:25, 92.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.19968343]\n",
      "[-0.20771694]\n",
      "[-0.19968343]\n",
      "INFO:tensorflow:Assets written to: model_15_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████▊                             | 16/25 [20:39<15:27, 103.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03402591]\n",
      "[0.02755749]\n",
      "[0.03402591]\n",
      "INFO:tensorflow:Assets written to: model_16_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████                          | 17/25 [26:58<24:47, 185.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04971743]\n",
      "[-0.0567466]\n",
      "[-0.04971743]\n",
      "INFO:tensorflow:Assets written to: model_17_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████████████▎                      | 18/25 [28:29<18:22, 157.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02110827]\n",
      "[-0.027946]\n",
      "[-0.02110827]\n",
      "INFO:tensorflow:Assets written to: model_18_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████████▌                   | 19/25 [29:13<12:19, 123.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24748069]\n",
      "[0.2424416]\n",
      "[0.24748069]\n",
      "INFO:tensorflow:Assets written to: model_19_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████▊                | 20/25 [36:23<17:56, 215.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00742757]\n",
      "[-0.01417351]\n",
      "[-0.00742757]\n",
      "INFO:tensorflow:Assets written to: model_20_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████████             | 21/25 [37:00<10:47, 161.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.241588]\n",
      "[-6.29008]\n",
      "[-6.241588]\n",
      "INFO:tensorflow:Assets written to: model_21_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████████▎         | 22/25 [37:09<05:48, 116.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.891998]\n",
      "[-6.944845]\n",
      "[-6.891998]\n",
      "INFO:tensorflow:Assets written to: model_22_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████████▍      | 23/25 [37:29<02:54, 87.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.153094]\n",
      "[-6.200993]\n",
      "[-6.153094]\n",
      "INFO:tensorflow:Assets written to: model_23_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████▋   | 24/25 [38:06<01:12, 72.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.6115227]\n",
      "[-5.6557956]\n",
      "[-5.6115227]\n",
      "INFO:tensorflow:Assets written to: model_24_mm.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [38:49<00:00, 93.20s/it]\n"
     ]
    }
   ],
   "source": [
    "dt_tt = pd.DataFrame()\n",
    "callback1 = tf.keras.callbacks.EarlyStopping(monitor='mean_squared_error', patience=20)\n",
    "for i in tqdm(range(25)):\n",
    "    string = f'model_{i}_{stem}'\n",
    "    best_hp = tuner.get_best_hyperparameters(num_trials=25)[i]\n",
    "    model = build_model(best_hp)\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = 250, verbose = 0, callbacks = callback1)\n",
    "    # Predicting the Test set results\n",
    "    y_pred1 = model.predict(X_train)\n",
    "    y_pred2 = model.predict(X_val)\n",
    "    \n",
    "    try:\n",
    "        model_summary_string = get_model_summary(model)\n",
    "        out = open(string + '.txt','w')\n",
    "        out.write(model_summary_string)\n",
    "        out.close\n",
    "\n",
    "\n",
    "        mse2 = round(mean_squared_error(y_val, y_pred2),3)\n",
    "        mse1 = round(mean_squared_error(y_train, y_pred1),3)\n",
    "        mae2 = round(mean_absolute_error(y_val, y_pred2),3)\n",
    "        mae1 = round(mean_absolute_error(y_train, y_pred1),3)\n",
    "        cod = round(r2_score(y_train, y_pred1),3)\n",
    "        q2f1 = round(Q2f1(y_val, y_pred2, y_train),3)\n",
    "        q2f2 = round(Q2f2(y_val, y_pred2),3)\n",
    "        maec = maecr(y_val, y_pred2, y_train)\n",
    "        maec95 = maecr_95(y_val, y_pred2, y_train)\n",
    "        trop = tropsha(y_train, y_val, y_pred1, y_pred2)\n",
    "\n",
    "        dt_tt = dt_tt.append({'model' : 'model_'+str(i),\\\n",
    "                              'Activation_functions' : best_hp.get('Activation_functions'),\\\n",
    "                              'Optimzer' : best_hp.get('Optimzer'),\\\n",
    "                                'loss' : best_hp.get('loss'),\\\n",
    "                             'batch_size': best_hp.get('batch_size'),\\\n",
    "                             'num_layers' : best_hp.get('num_layers'),\\\n",
    "                             'MSE Train' : mse1, 'MSE Test' : mse2, \\\n",
    "                             'MAE Train ' : mae1, 'MAE Test' : mae2, \\\n",
    "                             'Coefficient of determination(train)': cod,\\\n",
    "                             'Q2f1' : q2f1, 'Q2f2' : q2f2,\\\n",
    "                             'MAE criteria' : maec, \\\n",
    "                            'MAE criteria (95%)' : maec95, \\\n",
    "                             'TROPSA criteria' : trop},\\\n",
    "                            ignore_index = True)\n",
    "    \n",
    "        model.save(string+str('.tf'),overwrite=True)\n",
    "        \n",
    "    except:\n",
    "        print(string, 'failed to generate')\n",
    "        strr = string+str('.tf')+\" failed to generate.\"\n",
    "        out = open(string + '.txt','w')\n",
    "        out.write(strr)\n",
    "        out.close\n",
    "        \n",
    "        try: \n",
    "            shutil.rmtree(string+str('.tf'))\n",
    "        except:\n",
    "            pass\n",
    "         \n",
    "dt_tt.to_csv(log_name+stem+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''from ann_visualizer.visualize import ann_viz\n",
    "model = tf.keras.models.load_model('model_1.tf')\n",
    "ann_viz(model, view=True, filename='network.gv', title='MyNeural Network')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
